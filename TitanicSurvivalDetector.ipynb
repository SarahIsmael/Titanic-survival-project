{"cells":[{"metadata":{"_uuid":"c65b92fb-b1d5-4c65-816a-ad6a9a911f73","_cell_guid":"a872b555-1c51-453e-a3f3-7601d3c88daa","trusted":true},"cell_type":"code","source":"# %% [code]\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, \nimport os\nimport sys\nimport shutil\nfrom scipy import stats # for Box-Cox Transformation\nfrom mlxtend.preprocessing import minmax_scaling # for min_max scaling\n\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns # Statistical library for data visualization\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,classification_report,roc_auc_score,log_loss\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n\n# %% [code]\n#The function check null value in the dataset\ndef checkNullValue(df):\n    missing_data=df.isnull()\n    for column in missing_data.columns.values.tolist():\n        print(column)\n        print(missing_data[column].value_counts(),missing_data[column].dtype)\n    return 0\n\n# %% [code]\n'''The fuction replace null value with average value of it's column if datatype is (int,float) or\nwith most ferequent value in that column if column datatype is (object)'''\ndef dataCleansing(df):\n    print(df.columns)\n    for column in df.columns:\n        if(df[column].dtype=='int64' or df[column].dtype=='float64'):\n            mean_column=df[column].mean()\n            df[column].replace(np.nan,mean_column,inplace=True)\n        elif(df[column].dtype=='object'):\n            frequent=df1[column].value_counts().idxmax()\n            df[column].replace(np.nan,frequent,inplace=True)\n    return df\n\n# %% [code]\n#This fuction convert categorical value to a numerical value\ndef dummyFunc(df,list1):\n    for column in df.columns:\n        if(column in list1):\n            dummy=pd.get_dummies(df[column],prefix=column)\n            df=pd.concat([df,dummy],axis=1)\n            df.drop(column,inplace=True,axis=1)\n    return df\n\n# %% [code]\n#This function convert string title to numerical value using mapping\ndef createTitle(df):\n    df['Title']=df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n    df=df.drop(['Name'],axis=1)\n    title_mapping={'Mr':1,'Miss':2,'Mrs':3,'Master':1,'Lady':2,'Sir':1,'Capt':1,'Major':1}\n    df['Title_num']=df['Title'].map(title_mapping)\n    df['Title_num']=df['Title_num'].fillna(0)\n    df['Title_num']=df['Title_num'].map(int)\n    return df \n\n# %% [code]\n#This function convert age column from continous value to discrete value using if-else statement\ndef ageRange(df):\n    #p=sns.FacetGrid(df,col='Survived')\n    #p.map(plt.hist,'Age',bins=20)\n    #df['AgeRange'] = pd.cut(df['Age'], 6)\n    #df[['AgeRange','Survived']].groupby(['AgeRange'],as_index=False).mean().sort_values(by='AgeRange',ascending=True)\n    \n    df.loc[df['Age']<=13.68,'AgeRange']=1\n    df.loc[(df['Age']>13.68)&(df['Age']<=26.94),'AgeRange']=2\n    df.loc[(df['Age'] >26.94) & (df['Age']<=40.21),'AgeRange']=3   \n    df.loc[(df['Age'] >40.21) & (df['Age']<=53.47),'AgeRange']=4\n    df.loc[(df['Age'] >53.47) & (df['Age']<=66.73),'AgeRange']=5\n    df.loc[(df['Age'] >66.73) & (df['Age']<=80.0),'AgeRange']=6\n    df.loc[(df['Age']>80.0),'AgeRange']=0\n    return df\n\n# %% [code]\n#In this function we try to find family number for each person,call createTitles and ageRange Func\ndef column_manipulation(df):\n    df['Family']=df['SibSp']+df['Parch']+1\n    df=df.drop(['SibSp','Parch'],axis=1)\n    return df\n\n# %% [code]\n#This function call dataCleansing and dummyFunc for the dataset\ndef dataFrameManu(df,list1):\n    #print(\"description about the data frame\")\n    #print(df.describe(include=\"all\"))\n    #to count null value in each column\n    checkNullValue(df)\n    df_cleansing=dataCleansing(df)\n    df_dummy=dummyFunc(df_cleansing,list1)\n    df_title=createTitle(df_dummy)\n    df_age=ageRange(df_title)\n    new_df=column_manipulation(df_age)\n    return new_df\n\n# %% [code]\nif __name__==\"__main__\":\n    df1=pd.read_csv(\"../input/titanic/train.csv\")\n    df2=pd.read_csv(\"../input/titanic/test.csv\")\n    # These are categorical features and we need to convert them to numerical features\n    list1=['Pclass','Sex','Embarked']\n    #survive_gender is a varaible display the mount of female survived and male which are servived\n    survive_gender=df1[['Sex','Survived']].groupby(['Sex'],as_index=False).mean().sort_values('Survived',ascending=False)\n    print(survive_gender)\n\n# %% [code]\n    if not os.path.exists('outputset'):\n        os.makedirs('outputset') \n    \n        print(\"processing training set\")\n        df1_new=dataFrameManu(df1,list1)\n        print(\"Traning set after data preprocessing\",df1_new)\n\n        print(\"processing test set\")\n        df2_new=dataFrameManu(df2,list1)\n        print(\"Test set after data preprocessing\",df2_new)\n    \n    # save datasets after preprocessed \n    df1_new.to_csv('outputset/Trainset.csv',index=False)\n    df2_new.to_csv('outputset/Testset.csv',index=False)\n\n# %% [code]\n\n    df1_new=pd.read_csv('/kaggle/working/outputset/Trainset.csv')\n    df2_new=pd.read_csv('/kaggle/working/outputset/Testset.csv')\n\n    # %% [code]\n    y_train=df1_new['Survived']\n    x_train=df1_new.drop(['Title','Survived','PassengerId','Cabin','Ticket','Age'],axis=1)\n    x_test=df2_new.drop(['Title','PassengerId','Cabin','Ticket','Age'],axis=1)\n\n    # %% [code]\n    logistic=LogisticRegression()\n    logistic.fit(x_train,y_train)\n    y_pred=logistic.predict(x_test)\n    logistic_acc=round(logistic.score(x_train,y_train)*100,2)\n    print('accuracy',logistic_acc)\n\n    # %% [markdown]\n    # \n\n    # %% [code]\n    classifier=RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=0)\n    classifier.fit(x_train,y_train)\n    y_pred_forest=classifier.predict(x_test)\n    RForest_acc=round(classifier.score(x_train,y_train)*100,2)\n    print('accuracy',RForest_acc)\n\n    # %% [code]\n    boost_classifier=AdaBoostClassifier(n_estimators = 100, random_state = 0)\n    boost_classifier.fit(x_train,y_train)\n    y_pred_boost=boost_classifier.predict(x_test)\n    AdaBoost_acc=round(boost_classifier.score(x_train,y_train)*100,2)\n    print('accuracy',AdaBoost_acc)\n\n    # %% [code]\n    boosting_classifier=GradientBoostingClassifier(n_estimators = 100)\n    boosting_classifier.fit(x_train,y_train)\n    y_pred_boosting=boosting_classifier.predict(x_test)\n    GBoosting_acc=round(boosting_classifier.score(x_train,y_train)*100,2)\n    print('accuracy',GBoosting_acc)\n\n    # %% [code]\n    SVMachine=SVC()\n    SVMachine.fit(x_train,y_train)\n    y_pred_SV=SVMachine.predict(x_test)\n    SVM_acc=round(SVMachine.score(x_train,y_train)*100,2)\n    print('accurancy',SVM_acc)\n\n    # %% [code]\n    evaluation={'model':['Logistic','RandomForest','AdaBoost','GradientBoosting','SVM'],'Accuracy':[logistic_acc,RForest_acc,AdaBoost_acc,GBoosting_acc,SVM_acc]}\n    model=pd.DataFrame(evaluation)\n    model.sort_values('Accuracy',ascending=False)\n\n    # %% [code]\n    #os.remove('submission1.csv')\n\n    # %% [code]\n    submission1=pd.DataFrame({'PassengerId':df2_new['PassengerId'],'Survived':y_pred_forest})\n    submission1.to_csv('submission1.csv',index=False)\n\n# %% [code]\nprint(submission1)\n\n# %% [code]\nsubmission2=pd.DataFrame({'PassengerId':df2_new['PassengerId'],'Survived':y_pred_boosting})\nsubmission2.to_csv('submission2.csv',index=False)\n\n# %% [code]\nsubmission3=pd.DataFrame({'PassengerId':df2_new['PassengerId'],'Survived':y_pred_boost})\nsubmission3.to_csv('submission3.csv',index=False)","execution_count":1,"outputs":[{"output_type":"stream","text":"      Sex  Survived\n0  female  0.742038\n1    male  0.188908\nprocessing training set\nPassengerId\nFalse    891\nName: PassengerId, dtype: int64 bool\nSurvived\nFalse    891\nName: Survived, dtype: int64 bool\nPclass\nFalse    891\nName: Pclass, dtype: int64 bool\nName\nFalse    891\nName: Name, dtype: int64 bool\nSex\nFalse    891\nName: Sex, dtype: int64 bool\nAge\nFalse    714\nTrue     177\nName: Age, dtype: int64 bool\nSibSp\nFalse    891\nName: SibSp, dtype: int64 bool\nParch\nFalse    891\nName: Parch, dtype: int64 bool\nTicket\nFalse    891\nName: Ticket, dtype: int64 bool\nFare\nFalse    891\nName: Fare, dtype: int64 bool\nCabin\nTrue     687\nFalse    204\nName: Cabin, dtype: int64 bool\nEmbarked\nFalse    889\nTrue       2\nName: Embarked, dtype: int64 bool\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\nTraning set after data preprocessing      PassengerId  Survived        Age            Ticket     Fare Cabin  \\\n0              1         0  22.000000         A/5 21171   7.2500    G6   \n1              2         1  38.000000          PC 17599  71.2833   C85   \n2              3         1  26.000000  STON/O2. 3101282   7.9250    G6   \n3              4         1  35.000000            113803  53.1000  C123   \n4              5         0  35.000000            373450   8.0500    G6   \n..           ...       ...        ...               ...      ...   ...   \n886          887         0  27.000000            211536  13.0000    G6   \n887          888         1  19.000000            112053  30.0000   B42   \n888          889         0  29.699118        W./C. 6607  23.4500    G6   \n889          890         1  26.000000            111369  30.0000  C148   \n890          891         0  32.000000            370376   7.7500    G6   \n\n     Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  Embarked_C  \\\n0           0         0         1           0         1           0   \n1           1         0         0           1         0           1   \n2           0         0         1           1         0           0   \n3           1         0         0           1         0           0   \n4           0         0         1           0         1           0   \n..        ...       ...       ...         ...       ...         ...   \n886         0         1         0           0         1           0   \n887         1         0         0           1         0           0   \n888         0         0         1           1         0           0   \n889         1         0         0           0         1           1   \n890         0         0         1           0         1           0   \n\n     Embarked_Q  Embarked_S Title  Title_num  AgeRange  Family  \n0             0           1    Mr          1       2.0       2  \n1             0           0   Mrs          3       3.0       2  \n2             0           1  Miss          2       2.0       1  \n3             0           1   Mrs          3       3.0       2  \n4             0           1    Mr          1       3.0       1  \n..          ...         ...   ...        ...       ...     ...  \n886           0           1   Rev          0       3.0       1  \n887           0           1  Miss          2       2.0       1  \n888           0           1  Miss          2       3.0       4  \n889           0           0    Mr          1       2.0       1  \n890           1           0    Mr          1       3.0       1  \n\n[891 rows x 18 columns]\nprocessing test set\nPassengerId\nFalse    418\nName: PassengerId, dtype: int64 bool\nPclass\nFalse    418\nName: Pclass, dtype: int64 bool\nName\nFalse    418\nName: Name, dtype: int64 bool\nSex\nFalse    418\nName: Sex, dtype: int64 bool\nAge\nFalse    332\nTrue      86\nName: Age, dtype: int64 bool\nSibSp\nFalse    418\nName: SibSp, dtype: int64 bool\nParch\nFalse    418\nName: Parch, dtype: int64 bool\nTicket\nFalse    418\nName: Ticket, dtype: int64 bool\nFare\nFalse    417\nTrue       1\nName: Fare, dtype: int64 bool\nCabin\nTrue     327\nFalse     91\nName: Cabin, dtype: int64 bool\nEmbarked\nFalse    418\nName: Embarked, dtype: int64 bool\nIndex(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'df3_new' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f22bd602c9c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processing test set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mdf2_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataFrameManu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test set after data preprocessing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf3_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# save datasets after preprocessed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df3_new' is not defined"]}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}